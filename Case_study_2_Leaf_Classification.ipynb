{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Case_study_2_Leaf_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnlov+jEr+O6g8yEb9aBCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koyomin9zx/CS114.K21-Machine-Learning/blob/master/Case_study_2_Leaf_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exU3gz6AQA0h",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14HlcP5NQMJm",
        "colab_type": "text"
      },
      "source": [
        "download dataset & extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ofeR5zQNws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget  https://archive.ics.uci.edu/ml/machine-learning-databases/00338/Folio%20Leaf%20Dataset.rar\n",
        "!unrar x \"/content/Folio Leaf Dataset.rar\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgdeqvHSggl",
        "colab_type": "text"
      },
      "source": [
        "import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ScZvnCdzKm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imutils import paths\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.externals import joblib\n",
        "import cv2\n",
        "from keras import models, optimizers\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkv2E536Sem4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lấy các đường dẫn đến ảnh.\n",
        "image_path = list(paths.list_images('Folio Leaf Dataset/Folio'))\n",
        "\n",
        "# Đổi vị trí ngẫu nhiên các đường dẫn ảnh\n",
        "random.shuffle(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIGlx6IKTDkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đường dẫn ảnh sẽ là 'Folio Leaf Dataset/Folio/tên_loài_hoa/tên_ảnh' ví dụ 'Folio Leaf Dataset/Folio/pomme jacquot/20150324_143055.jpg' nên p.split(os.path.sep)[-2] sẽ lấy ra được tên loài hoa\n",
        "labels = [p.split(os.path.sep)[-2] for p in image_path]\n",
        "# Chuyển tên các loài hoa thành số\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff7DGafRT37O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected layer ở cuối.\n",
        "model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKYNiBYaUAC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load ảnh và resize về đúng kích thước mà VGG 16 cần là (224,224)\n",
        "list_image = []\n",
        "for (j, imagePath) in enumerate(image_path):\n",
        "    image = load_img(imagePath, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    \n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = imagenet_utils.preprocess_input(image)\n",
        "    \n",
        "    list_image.append(image)\n",
        "    \n",
        "list_image = np.vstack(list_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAg_R5GEVR2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dùng pre-trained model để lấy ra các feature của ảnh\n",
        "features = model.predict(list_image)\n",
        "\n",
        "# Giống bước flatten trong CNN, chuyển từ tensor 3 chiều sau ConvNet sang vector 1 chiều\n",
        "features = features.reshape((features.shape[0], 512*7*7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yuyxwBqVv0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chia traing set, test set tỉ lệ 80-20\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXK3YXMlXFK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "1e7e4080-5ece-4110-f540-1225db1b38f3"
      },
      "source": [
        "#train với linearSVM\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIg2FJVkXO8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "0ad7477a-d61e-4db9-9f07-3de6312a1584"
      },
      "source": [
        "predictions_SVM=svm_linear.predict(X_test)\n",
        "print(classification_report(y_test,predictions_SVM))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         4\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       1.00      1.00      1.00         6\n",
            "           5       1.00      0.75      0.86         4\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         5\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         4\n",
            "          10       0.67      1.00      0.80         2\n",
            "          11       1.00      1.00      1.00         2\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "          15       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00         6\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         3\n",
            "          19       1.00      1.00      1.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          21       1.00      1.00      1.00         7\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         2\n",
            "          24       1.00      1.00      1.00         1\n",
            "          25       1.00      1.00      1.00         4\n",
            "          26       1.00      1.00      1.00         5\n",
            "          27       1.00      1.00      1.00         3\n",
            "          28       1.00      1.00      1.00         5\n",
            "          29       1.00      1.00      1.00         5\n",
            "          30       1.00      1.00      1.00         5\n",
            "          31       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.99       128\n",
            "   macro avg       0.99      0.99      0.99       128\n",
            "weighted avg       0.99      0.99      0.99       128\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lkxOfBPfV2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected layer ở cuối.\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "# Dùng pre-trained model để lấy ra các feature của ảnh\n",
        "features = model.predict(list_image)\n",
        "\n",
        "# Giống bước flatten trong CNN, chuyển từ tensor 3 chiều sau ConvNet sang vector 1 chiều\n",
        "#features = features.reshape((features.shape[0], 512*7*7))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}